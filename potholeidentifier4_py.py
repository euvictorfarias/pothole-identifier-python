# -*- coding: utf-8 -*-
"""PotholeIdentifier4.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_GqaHng9Twd1TLpPfV_9PoJIDbg-9h3Y

# **Cross Validation**

##Leitura de Imagens do Drive
"""

import pandas as pd;
import numpy as np;
import cv2 as cv;

imagesPath = '/content/drive/MyDrive/ColabNotebooks/Images/all_data/';
docPath = '/content/drive/MyDrive/ColabNotebooks/Documents/';

trainIds = pd.read_csv((docPath + 'train_ids_labels.csv'));
trainImages = [];

for index in range(0, len(trainIds)):
    label = trainIds['Image_ID'][index] + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    trainImages.append({'Image': image, 'Pothole': trainIds['Label'][index]});

testIds = pd.read_csv((docPath + 'test_ids_only.csv'));
testImages = [];

for id in testIds['Image_ID']:
    label = id + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    testImages.append((image, label));

trainImagesDF = pd.DataFrame(trainImages, columns=['Image', 'Pothole']);
testImagesDF = pd.DataFrame(testImages, columns=['Image', 'Label']);

"""##Gravação de imagens no Drive como arquivo binário"""

import pickle;

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents/trainFile.bin', 'wb');
pickle.dump(trainImagesDF, fileBin);
fileBin.close();

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents/testFile.bin', 'wb');
pickle.dump(testImagesDF, fileBin);
fileBin.close();

"""##Leitura de arquivo binário que contém as imagens salvas no Drive"""

import pickle;
from google.colab import drive;

drive.mount('/content/drive');

with(open('/content/drive/MyDrive/ColabNotebooks/Documents/trainFile.bin','rb')) as openfile:
  trainImagesDF = pickle.load(openfile);

with(open('/content/drive/MyDrive/ColabNotebooks/Documents/testFile.bin','rb')) as openfile:
  testImagesDF = pickle.load(openfile);

"""##Exemplo de Imagem importada"""

import matplotlib.pyplot as plt
plt.imshow(testImagesDF['Image'][0], cmap = plt.cm.gray)
plt.show()

"""# **Pré Processamento**

##Conversão de arquivos de imagens de DataFrame para Listas
"""

trainImagesList = trainImagesDF.values.tolist();
testImagesList = testImagesDF.values.tolist();

"""##Separação de imagens e labels de treinamento em listas"""

import cv2 as cv;
import numpy as np;

trainInputImages = [(image[0]/255.0) for image in trainImagesList];
trainLabels = np.array([label[1] for label in trainImagesList]);

"""##Split de arquivos de treinamento em variáveis"""

from sklearn.model_selection import train_test_split;
from tensorflow.keras import regularizers;
from tensorflow.keras.optimizers import Adam
import tensorflow as tf;
import numpy as np

REG = 0.001;
DROP = 0.1;

for x in range(2, 6):

  xTrain, xTest, yTrain, yTest = train_test_split(trainInputImages, trainLabels, 
                                                  test_size=0.1*x, random_state=42);
  xTrain = np.array(xTrain);
  xTest = np.array(xTest);
  xTrain = xTrain[..., tf.newaxis]
  xTest = xTest[..., tf.newaxis]

  yTestHot = tf.one_hot(yTest,2);
  yTrainHot = tf.one_hot(yTrain,2);

  model = tf.keras.Sequential();
  model.add(tf.keras.layers.Flatten());

  model.add(tf.keras.layers.Dense(768, activation='sigmoid', kernel_regularizer=regularizers.l2(REG)));
  model.add(tf.keras.layers.Dropout(DROP));

  model.add(tf.keras.layers.Dense(2, activation='softmax'));

  model.compile(optimizer=Adam(learning_rate=5e-5), loss='categorical_crossentropy', metrics=['accuracy']);

  history = model.fit(xTrain,yTrainHot,epochs=500,validation_split=0.1*x,
                      callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', 
                                                                  min_delta=0, patience=100)]);

  MODEL_PATH = '/content/drive/MyDrive/ColabNotebooks/Documents4/Modelo' + str(x-1) + '/';
  HISTORY_PATH = '/content/drive/MyDrive/ColabNotebooks/Documents4/model_history' + str(x-1);

  model.save(MODEL_PATH);

  with open(HISTORY_PATH, 'wb') as file:
    pickle.dump(history.history,file)

import tensorflow as tf;

modelPath = "/content/drive/MyDrive/ColabNotebooks/Documents4/Modelo1";
model1 = tf.keras.models.load_model(modelPath, custom_objects=None, compile=True, options=None)

modelPath = "/content/drive/MyDrive/ColabNotebooks/Documents4/Modelo2";
model2 = tf.keras.models.load_model(modelPath, custom_objects=None, compile=True, options=None)

modelPath = "/content/drive/MyDrive/ColabNotebooks/Documents4/Modelo3";
model3 = tf.keras.models.load_model(modelPath, custom_objects=None, compile=True, options=None)

modelPath = "/content/drive/MyDrive/ColabNotebooks/Documents4/Modelo4";
model4 = tf.keras.models.load_model(modelPath, custom_objects=None, compile=True, options=None)

from google.colab import drive;

drive.mount('/content/drive');

import pickle;

with(open('/content/drive/MyDrive/ColabNotebooks/Documents4/model_history1','rb')) as openfile:
  history1 = pickle.load(openfile);

with(open('/content/drive/MyDrive/ColabNotebooks/Documents4/model_history2','rb')) as openfile:
  history2 = pickle.load(openfile);
  
with(open('/content/drive/MyDrive/ColabNotebooks/Documents4/model_history3','rb')) as openfile:
  history3 = pickle.load(openfile);

with(open('/content/drive/MyDrive/ColabNotebooks/Documents4/model_history4','rb')) as openfile:
  history4 = pickle.load(openfile);

model1.evaluate(xTest,yTestHot,verbose=2)

max(history1['accuracy'])

max(history1['val_accuracy'])

import matplotlib.pyplot as plt;

training_acc = history1['accuracy']
val_acc = history1['val_accuracy']

epoch_count = range(1, len(training_acc) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_acc, 'r--')
plt.plot(epoch_count, val_acc, 'b-')
plt.legend(['Precisão de treinamento', 'Precisão de validação'])
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.grid()
plt.show()

model2.evaluate(xTest,yTestHot,verbose=2)

max(history2['accuracy'])

max(history2['val_accuracy'])

import matplotlib.pyplot as plt;

training_acc = history2['accuracy']
val_acc = history2['val_accuracy']

epoch_count = range(1, len(training_acc) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_acc, 'r--')
plt.plot(epoch_count, val_acc, 'b-')
plt.legend(['Precisão de treinamento', 'Precisão de validação'])
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.grid()
plt.show()

model3.evaluate(xTest,yTestHot,verbose=2)

max(history3['accuracy'])

max(history3['val_accuracy'])

import matplotlib.pyplot as plt;

training_acc = history3['accuracy']
val_acc = history3['val_accuracy']

epoch_count = range(1, len(training_acc) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_acc, 'r--')
plt.plot(epoch_count, val_acc, 'b-')
plt.legend(['Precisão de treinamento', 'Precisão de validação'])
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.grid()
plt.show()

model4.evaluate(xTest,yTestHot,verbose=2)

max(history4['accuracy'])

max(history4['val_accuracy'])

import matplotlib.pyplot as plt;

training_acc = history4['accuracy']
val_acc = history4['val_accuracy']

epoch_count = range(1, len(training_acc) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_acc, 'r--')
plt.plot(epoch_count, val_acc, 'b-')
plt.legend(['Precisão de treinamento', 'Precisão de validação'])
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.grid()
plt.show()