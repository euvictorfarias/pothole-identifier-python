# -*- coding: utf-8 -*-
"""PotholeIdentifier3.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQB-Sqdz7681AiVI1z1ecIg7qCl2pVy7

# **Importação de Imagens**

##Leitura de Imagens do Drive
"""

import pandas as pd;
import numpy as np;
import cv2 as cv;

imagesPath = '/content/drive/MyDrive/ColabNotebooks/Images/all_data/';
docPath = '/content/drive/MyDrive/ColabNotebooks/Documents/';

trainIds = pd.read_csv((docPath + 'train_ids_labels.csv'));
trainImages = [];

for index in range(0, len(trainIds)):
    label = trainIds['Image_ID'][index] + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    trainImages.append({'Image': image, 'Pothole': trainIds['Label'][index]});

testIds = pd.read_csv((docPath + 'test_ids_only.csv'));
testImages = [];

for id in testIds['Image_ID']:
    label = id + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    testImages.append((image, label));

trainImagesDF = pd.DataFrame(trainImages, columns=['Image', 'Pothole']);
testImagesDF = pd.DataFrame(testImages, columns=['Image', 'Label']);

"""##Gravação de imagens no Drive como arquivo binário"""

import pickle;

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents3/trainFile.bin', 'wb');
pickle.dump(trainImagesDF, fileBin);
fileBin.close();

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents3/testFile.bin', 'wb');
pickle.dump(testImagesDF, fileBin);
fileBin.close();

"""##Leitura de arquivo binário que contém as imagens salvas no Drive"""

import pickle;
from google.colab import drive;

drive.mount('/content/drive');

with(open('/content/drive/MyDrive/ColabNotebooks/Documents3/trainFile.bin','rb')) as openfile:
  trainImagesDF = pickle.load(openfile);

with(open('/content/drive/MyDrive/ColabNotebooks/Documents3/testFile.bin','rb')) as openfile:
  testImagesDF = pickle.load(openfile);

"""##Exemplo de Imagem importada"""

testImagesDF.shape

import matplotlib.pyplot as plt
plt.imshow(testImagesDF['Image'][0], cmap = plt.cm.gray)
plt.show()

"""# **Pré Processamento**

##Conversão de arquivos de imagens de DataFrame para Listas
"""

trainImagesList = trainImagesDF.values.tolist();
testImagesList = testImagesDF.values.tolist();

trainImagesList

"""##Separação de imagens e labels de treinamento em listas"""

import cv2 as cv;
import numpy as np;

trainInputImages = [(image[0]/255.0) for image in trainImagesList];
trainLabels = np.array([label[1] for label in trainImagesList]);

"""##Split de arquivos de treinamento em variáveis"""

from sklearn.model_selection import train_test_split;

xTrain, xTest, yTrain, yTest = train_test_split(trainInputImages, trainLabels, test_size=0.2, random_state=42)

"""##Transformação de variáveis de treinamento em listas e adição de uma dimensão"""

import tensorflow as tf;
import numpy as np

xTrain = np.array(xTrain);
xTest = np.array(xTest);

xTrain = xTrain[..., tf.newaxis]
xTest = xTest[..., tf.newaxis]

"""##Encoding dos labels nas variáveis de treinamento"""

import tensorflow as tf;

yTestHot = tf.one_hot(yTest,2);
yTrainHot = tf.one_hot(yTrain,2);

"""# **Treinamento do Modelo**

##Aquisição do modelo de treinamento
"""

import tensorflow as tf;
from tensorflow.keras import regularizers;
from tensorflow.keras.optimizers import Adam

REG = 0.001;
DROP = 0.1;

model = tf.keras.Sequential();
model.add(tf.keras.layers.Flatten());

model.add(tf.keras.layers.Dense(768, activation='sigmoid', kernel_regularizer=regularizers.l2(REG)));
model.add(tf.keras.layers.Dropout(DROP));

model.add(tf.keras.layers.Dense(2, activation='softmax'));

model.compile(optimizer=Adam(learning_rate=5e-5), loss='categorical_crossentropy', metrics=['accuracy']);

"""##Aquisição do arquivo history"""

history = model.fit(xTrain,yTrainHot,epochs=1000,validation_split=0.2,
                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', 
                                                                min_delta=0, patience=100)]);

"""##Resultado para as variáveis de treinamento durante o treinamento"""

model.evaluate(xTest,yTestHot,verbose=2)

"""##Resultado para as variáveis de teste durante o treinamento"""

model.evaluate(xTrain,yTrainHot,verbose=2)

"""##Gravação do arquivo de modelo no Drive"""

model.save('/content/drive/MyDrive/ColabNotebooks/Documents/');

"""##Leitura do arquivo de modelo no Drive"""

import tensorflow as tf;

modelPath = "/content/drive/MyDrive/ColabNotebooks/Documents/";
model = tf.saved_model.load(modelPath);

"""##Gravação do arquivo history no Drive"""

with open('/content/drive/MyDrive/ColabNotebooks/Documents/model_history','wb') as file:
    pickle.dump(history.history,file)

"""##Leitura do arquivo history no Drive"""

import pickle;

with(open('/content/drive/MyDrive/ColabNotebooks/Documents/model_history','rb')) as openfile:
  history = pickle.load(openfile);

"""##Exibição das colunas do arquivo history"""

history.history.keys()

"""# **Resultados do Modelo**

##Erros durante treinamento e validação
"""

import matplotlib.pyplot as plt;

training_loss = history.history['loss']
val_loss = history.history['val_loss']

epoch_count = range(1, len(training_loss) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_loss, 'r--')
plt.plot(epoch_count, val_loss, 'b-')
plt.legend(['Erro de treinamento', 'Erro de validação'])
plt.xlabel('Época')
plt.ylabel('Erro')
plt.grid()
plt.show()

"""##Previsão durante treinamento e validação"""

import matplotlib.pyplot as plt;

training_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epoch_count = range(1, len(training_acc) + 1)
plt.figure(figsize=(14,10))
plt.plot(epoch_count, training_acc, 'r--')
plt.plot(epoch_count, val_acc, 'b-')
plt.legend(['Precisão de treinamento', 'Precisão de validação'])
plt.xlabel('Época')
plt.ylabel('Precisão')
plt.grid()
plt.show()

"""#**Testes do Modelo**

##Conversão do modelo para tf.lite
"""

import tensorflow as tf;

converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/MyDrive/ColabNotebooks/Documents/');
tfliteModel = converter.convert();

"""##Gravação do modelo tf.lite no Drive"""

with open('/content/drive/MyDrive/ColabNotebooks/Documents/modelTfLite.tflite', 'wb') as file:
  file.write(tfliteModel);

"""##Leitura do modelo tf.lite do Drive como interpretador"""

import tensorflow as tf;
interpreter = tf.lite.Interpreter('/content/drive/MyDrive/ColabNotebooks/Documents/modelTfLite.tflite');
interpreter.allocate_tensors();

import cv2 as cv;
import numpy as np;
import matplotlib.pyplot as plt

index = 0;
imagesPath = '/content/drive/MyDrive/ColabNotebooks/Images/all_data/';
image = testImagesDF['Image'][index];
label = '/content/drive/MyDrive/ColabNotebooks/Images/all_data/' + testImagesDF['Label'][index];

testImageForModel = cv.imread(label, 1);
testImageForModel2 = cv.cvtColor(testImageForModel, cv.COLOR_RGB2GRAY);
testImageForModel2 = cv.resize(testImageForModel2, (160, 120));
testImageForModel3 = np.array(testImageForModel2, dtype=np.float32) / 255.0;
testImageForModel3 = testImageForModel3[np.newaxis, ..., np.newaxis];

interpreter.set_tensor(0, testImageForModel3)
interpreter.invoke()
output = interpreter.get_tensor(10)

output

output.argmax()

from google.colab.patches import cv2_imshow;

cv2_imshow(testImageForModel);

cv2_imshow(testImageForModel2);

"""# **Escrita**

##Tópicos:
- Processamento de Imagens;
- Redes Neurais (Geral)
- Rede Neural MLP
"""