# -*- coding: utf-8 -*-
"""PotholeIdentifier2.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ERP-8O4WHLrbCEySPl9TlKPoGAiGwZwp

# **Treinamento de 3 modelos**

##Leitura de Imagens do Drive
"""

import pandas as pd;
import numpy as np;
import cv2 as cv;

imagesPath = '/content/drive/MyDrive/ColabNotebooks/Images/all_data/';
docPath = '/content/drive/MyDrive/ColabNotebooks/Documents/';

trainIds = pd.read_csv((docPath + 'train_ids_labels.csv'));
trainImages = [];

for index in range(0, len(trainIds)):
    label = trainIds['Image_ID'][index] + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    trainImages.append({'Image': image, 'Pothole': trainIds['Label'][index]});

testIds = pd.read_csv((docPath + 'test_ids_only.csv'));
testImages = [];

for id in testIds['Image_ID']:
    label = id + '.JPG';
    image = cv.imread((imagesPath + label), 1);
    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY);
    image = cv.resize(image, (160, 120));
    testImages.append((image, label));

trainImagesDF = pd.DataFrame(trainImages, columns=['Image', 'Pothole']);
testImagesDF = pd.DataFrame(testImages, columns=['Image', 'Label']);

"""##Gravação de imagens no Drive como arquivo binário"""

import pickle;

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents/trainFile.bin', 'wb');
pickle.dump(trainImagesDF, fileBin);
fileBin.close();

fileBin = open('/content/drive/MyDrive/ColabNotebooks/Documents/testFile.bin', 'wb');
pickle.dump(testImagesDF, fileBin);
fileBin.close();

"""##Leitura de arquivo binário que contém as imagens salvas no Drive"""

import pickle;
from google.colab import drive;

drive.mount('/content/drive');

with(open('/content/drive/MyDrive/ColabNotebooks/Documents/trainFile.bin','rb')) as openfile:
  trainImagesDF = pickle.load(openfile);

with(open('/content/drive/MyDrive/ColabNotebooks/Documents/testFile.bin','rb')) as openfile:
  testImagesDF = pickle.load(openfile);

"""##Exemplo de Imagem importada"""

import matplotlib.pyplot as plt
plt.imshow(testImagesDF['Image'][0], cmap = plt.cm.gray)
plt.show()

"""# **Pré Processamento**

##Conversão de arquivos de imagens de DataFrame para Listas
"""

trainImagesList = trainImagesDF.values.tolist();
testImagesList = testImagesDF.values.tolist();

"""##Separação de imagens e labels de treinamento em listas"""

import cv2 as cv;
import numpy as np;

trainInputImages = [(image[0]/255.0) for image in trainImagesList];
trainLabels = np.array([label[1] for label in trainImagesList]);

"""##Split de arquivos de treinamento em variáveis"""

from sklearn.model_selection import train_test_split;

xTrain, xTest, yTrain, yTest = train_test_split(trainInputImages, trainLabels, test_size=0.2, random_state=42)

"""##Transformação de variáveis de treinamento em listas e adição de uma dimensão"""

import tensorflow as tf;
import numpy as np

xTrain = np.array(xTrain);
xTest = np.array(xTest);

xTrain = xTrain[..., tf.newaxis]
xTest = xTest[..., tf.newaxis]

"""##Encoding dos labels nas variáveis de treinamento"""

import tensorflow as tf;

yTestHot = tf.one_hot(yTest,2);
yTrainHot = tf.one_hot(yTrain,2);

"""# **Treinamento do Modelo**

##Aquisição do modelo de treinamento
"""

!pip install keras-tuner --upgrade

import tensorflow as tf;
from tensorflow.keras import regularizers;
from tensorflow.keras.optimizers import Adam

def build_model(hp):
  REG = 0.001;
  DROP = 0.1;

  model = tf.keras.Sequential();
  model.add(tf.keras.layers.Flatten());

  model.add(tf.keras.layers.Dense(768, activation='sigmoid', kernel_regularizer=regularizers.l2(REG)));
  model.add(tf.keras.layers.Dropout(DROP));

  model.add(tf.keras.layers.Dense(2, activation='softmax'));

  model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[5e-5, 5e-6, 1e-5, 1e-6])), loss='categorical_crossentropy', metrics=['accuracy']);

  return model

import keras_tuner as kt;
from kerastuner.tuners import RandomSearch
from tensorflow import keras;

tuner = kt.RandomSearch(
    build_model,
    objective="val_accuracy",
    max_trials=3,
    overwrite=True,
    directory="/content/drive/MyDrive/ColabNotebooks/Documents2",
    project_name="saved_model",
)

tuner.search(xTrain, yTrainHot, epochs=500, validation_split=0.2,
             callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', 
                                                           min_delta=0, patience=100)]);

bestModels = tuner.get_best_models(num_models=1)
highestScoreModel= bestModels[0]

highestScoreModel.fit(x=xTrain, y=yTrainHot, batch_size=64, epochs=500, 
                      verbose=1, validation_split=0.2)

highestScoreModel.save("/content/drive/MyDrive/ColabNotebooks/Documents2")

tuner.results_summary()

model = tuner.get_best_models(num_models=1)

model[0].evaluate(xTest,yTestHot,verbose=2)

model[0].evaluate(xTrain,yTrainHot,verbose=2)

model[0].save('/content/drive/MyDrive/ColabNotebooks/Documents2');

import tensorflow as tf;

converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/MyDrive/ColabNotebooks/Documents2/')
tflite_model = converter.convert()

with open('/content/drive/MyDrive/ColabNotebooks/Documents2/mlp_model.tflite', 'wb') as f:
    f.write(tflite_model)

history = model[0].history

tuner.oracle.get_best_trials()[0].trial_id

from google.colab import drive;

drive.mount('/content/drive');